{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd500df",
   "metadata": {},
   "source": [
    "The following code uses a 2D Convolutional Neural Network (CNN) to detect whether a page is being flipped or not based on a single image. The model consists of two convolutional layers, each using three 3×3 filters, followed by max pooling layers to reduce spatial dimensions and retain the most important features.\n",
    "\n",
    "During training, the input images are processed in batches of 32 images, resulting in 75 batches per epoch. For each batch, the model performs forward propagation, computes the loss, and updates the filter and dense layer weights using gradient descent. This process is repeated across 10 epochs, with the learned weights from each epoch carried forward to the next.\n",
    "After each epoch, the model is evaluated on a separate testing dataset to compute validation accuracy and validation loss. These testing images are not used for learning and do not affect the model’s weights. After training is complete, the final learned weights are used to generate predictions on the full test dataset.\n",
    "\n",
    "The model achieves a Test F1 score of 97.42%, indicating strong performance. The F1 score is an appropriate evaluation metric for this problem because it balances precision and recall, accounting for both false positives (incorrectly detecting a page flip) and false negatives (missing an actual page flip), which are both important in the context of page flip detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381828b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2392 images belonging to 2 classes.\n",
      "Found 597 images belonging to 2 classes.\n",
      "Training images: 2392\n",
      "Testing images: 597\n",
      "Class indices: {'flip': 0, 'notflip': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2700</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m84\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │            \u001b[38;5;34m84\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2700\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m86,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,633</span> (338.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m86,633\u001b[0m (338.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,633</span> (338.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m86,633\u001b[0m (338.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75/75 - 20s - 263ms/step - accuracy: 0.7115 - loss: 0.5412 - val_accuracy: 0.8124 - val_loss: 0.4180\n",
      "Epoch 2/10\n",
      "75/75 - 18s - 246ms/step - accuracy: 0.8997 - loss: 0.2841 - val_accuracy: 0.9179 - val_loss: 0.2368\n",
      "Epoch 3/10\n",
      "75/75 - 18s - 240ms/step - accuracy: 0.9323 - loss: 0.1715 - val_accuracy: 0.9012 - val_loss: 0.2244\n",
      "Epoch 4/10\n",
      "75/75 - 18s - 240ms/step - accuracy: 0.9640 - loss: 0.1142 - val_accuracy: 0.9246 - val_loss: 0.1766\n",
      "Epoch 5/10\n",
      "75/75 - 18s - 236ms/step - accuracy: 0.9749 - loss: 0.0771 - val_accuracy: 0.9631 - val_loss: 0.1141\n",
      "Epoch 6/10\n",
      "75/75 - 18s - 235ms/step - accuracy: 0.9841 - loss: 0.0579 - val_accuracy: 0.9414 - val_loss: 0.1536\n",
      "Epoch 7/10\n",
      "75/75 - 18s - 236ms/step - accuracy: 0.9816 - loss: 0.0539 - val_accuracy: 0.9682 - val_loss: 0.1017\n",
      "Epoch 8/10\n",
      "75/75 - 18s - 244ms/step - accuracy: 0.9783 - loss: 0.0627 - val_accuracy: 0.9447 - val_loss: 0.1321\n",
      "Epoch 9/10\n",
      "75/75 - 19s - 248ms/step - accuracy: 0.9895 - loss: 0.0399 - val_accuracy: 0.9765 - val_loss: 0.0739\n",
      "Epoch 10/10\n",
      "75/75 - 18s - 236ms/step - accuracy: 0.9950 - loss: 0.0201 - val_accuracy: 0.9732 - val_loss: 0.0730\n",
      "Test F1 score: 0.9742\n"
     ]
    }
   ],
   "source": [
    "# Hide TensorFlow and Keras low level logs (GPU, device, paths)\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Hide Python warnings (Keras input shape warning, etc.)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import required packages after setting log level\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def clean_path(path_input):\n",
    "    \"\"\"\n",
    "    Remove unwanted quotes from copied macOS folder paths.\n",
    "    \"\"\"\n",
    "    return path_input.replace(\"'\", \"\").replace('\"', \"\").strip()\n",
    "\n",
    "\n",
    "def create_generators(train_dir, test_dir, img_size, batch_size):\n",
    "    \"\"\"\n",
    "    Create training and testing image generators for loading data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize pixel values from [0,255] to [0,1]\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "    # Generator for training images (shuffled)\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        directory=train_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Generator for test images (not shuffled)\n",
    "    test_gen = test_datagen.flow_from_directory(\n",
    "        directory=test_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_gen, test_gen\n",
    "\n",
    "\n",
    "def build_cnn_model(img_height, img_width):\n",
    "    \"\"\"\n",
    "    Build a simple 2 layer CNN with 3 filters each.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use an explicit Input layer to avoid warnings\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(img_height, img_width, 3)),\n",
    "\n",
    "        layers.Conv2D(filters=3, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(filters=3, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_f1(model, test_gen):\n",
    "    \"\"\"\n",
    "    Compute F1 score on the test set predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    test_gen.reset()\n",
    "    y_prob = model.predict(test_gen, verbose=0)\n",
    "    y_pred = (y_prob > 0.5).astype(\"int32\").ravel()\n",
    "    y_true = test_gen.classes\n",
    "\n",
    "    return f1_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MAIN EXECUTION\n",
    "# ===============================\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "img_size = (img_height, img_width)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "raw_train_dir = input(\"Paste training folder path: \")\n",
    "raw_test_dir = input(\"Paste testing folder path: \")\n",
    "\n",
    "train_dir = clean_path(raw_train_dir)\n",
    "test_dir = clean_path(raw_test_dir)\n",
    "\n",
    "train_gen, test_gen = create_generators(\n",
    "    train_dir, test_dir, img_size, batch_size\n",
    ")\n",
    "\n",
    "# Print only non sensitive info\n",
    "print(f\"Training images: {train_gen.samples}\")\n",
    "print(f\"Testing images: {test_gen.samples}\")\n",
    "print(\"Class indices:\", train_gen.class_indices)\n",
    "\n",
    "model = build_cnn_model(img_height, img_width)\n",
    "\n",
    "# Hide model summary if you want less output\n",
    "model.summary()\n",
    "\n",
    "# Train with less verbose output to reduce printed logs\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_gen,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "f1 = evaluate_f1(model, test_gen)\n",
    "print(f\"Test F1 score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env_tf",
   "language": "python",
   "name": "tf_env_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
